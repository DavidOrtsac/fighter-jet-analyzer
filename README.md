# ‚úàÔ∏è Fighter Jet Analyzer

> AI-powered sentiment analysis of fighter jet and aviation discussions from Reddit

A full-stack SaaS application that demonstrates real-world data pipeline architecture: **Apify ‚Üí Supabase ‚Üí OpenAI ‚Üí Next.js UI**

üîó **Live Demo:** [Coming Soon - Deploy to Vercel]

## üìã Table of Contents

- [Overview](#overview)
- [Tech Stack](#tech-stack)
- [Features](#features)
- [Setup Instructions](#setup-instructions)
- [Architecture Decisions](#architecture-decisions)
- [Scaling Considerations](#scaling-considerations)
- [Failure Handling Strategy](#failure-handling-strategy)
- [System Health Monitoring](#system-health-monitoring)
- [Screenshots](#screenshots)

---

## üéØ Overview

This application collects discussions about fighter jets and military aviation from Reddit, stores them in Supabase, analyzes sentiment using OpenAI's GPT-3.5, and displays the results in a modern web interface.

### Why Fighter Jets?

1. **High Engagement:** Aviation enthusiast communities produce detailed, opinionated content perfect for sentiment analysis
2. **Real Business Case:** Defense contractors and aviation companies use social listening to gauge public perception of aircraft programs
3. **Clear Entities:** Aircraft names (F-35, Su-57, F-22) are easy to extract and categorize
4. **Demonstrates Domain Flexibility:** Shows ability to work with specialized topics beyond generic social media

### Data Sources

- **r/FighterJets** - Dedicated fighter aircraft discussions
- **r/aviation** - General aviation community
- **r/WarplanePorn** - High-quality military aircraft content
- **r/hoggit** - Digital Combat Simulator (DCS) and flight simulation community

---

## üõ† Tech Stack

- **Frontend:** Next.js 16 (App Router), React 19, TypeScript, Tailwind CSS
- **Backend:** Next.js API Routes (serverless)
- **Database:** Supabase (PostgreSQL)
- **APIs:** 
  - Apify (Reddit scraping)
  - OpenAI GPT-3.5 (sentiment analysis)
- **Notifications:** react-hot-toast
- **Deployment:** Vercel

---

## ‚ú® Features

- üöÄ **One-Click Data Pipeline** - Automated scraping, storage, and analysis
- üéØ **Sentiment Analysis** - Positive/Negative/Neutral classification with AI summaries
- üîÑ **Retry Mechanism** - Automatic retry for failed analyses
- üìä **Status Tracking** - Real-time visibility into processing states
- üè• **Health Monitoring** - System health endpoint for uptime tracking
- üíÖ **Modern UI** - Responsive design with loading states and toast notifications

---

## üöÄ Setup Instructions

### Prerequisites

- Node.js 18+ installed
- Accounts for: Apify, Supabase, OpenAI

### Step 1: Clone & Install

```bash
git clone [your-repo-url]
cd apify-analyzer
npm install
```

### Step 2: Set Up Supabase

1. Create a new project at [supabase.com](https://supabase.com)
2. Go to SQL Editor and run the schema from `scripts/setup.sql`:

```sql
CREATE TABLE analyzed_data (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  source TEXT NOT NULL,
  content TEXT NOT NULL,
  analysis JSONB,
  sentiment TEXT,
  status TEXT CHECK (status IN ('pending', 'processing', 'completed', 'failed')) DEFAULT 'pending',
  analyzed_at TIMESTAMPTZ,
  error_message TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_created_at ON analyzed_data(created_at DESC);
CREATE INDEX idx_status ON analyzed_data(status);
CREATE INDEX idx_analyzed_at ON analyzed_data(analyzed_at DESC);
```

3. Copy your Project URL and anon key from Settings ‚Üí API

### Step 3: Get API Keys

- **Apify:** Settings ‚Üí Integrations ‚Üí API Token
- **OpenAI:** platform.openai.com ‚Üí API Keys
- **Supabase:** Already copied above

### Step 4: Configure Environment

Create `.env.local`:

```bash
# Apify Configuration
APIFY_API_TOKEN=your_apify_token

# OpenAI Configuration
OPENAI_API_KEY=your_openai_key

# Supabase Configuration
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_ANON_KEY=your_supabase_key

# Base URL (for API routes)
NEXT_PUBLIC_BASE_URL=http://localhost:3000
```

### Step 5: Run Development Server

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) and click "Run Data Pipeline"!

### Step 6: Deploy to Vercel

```bash
# Push to GitHub
git add .
git commit -m "Initial commit"
git push origin main

# Deploy via Vercel Dashboard
# 1. Import GitHub repo
# 2. Add all environment variables
# 3. Deploy!
```

---

## üèó Architecture Decisions

### 1. Schema Reasoning

**Decision:** Single table with status column and JSONB for analysis results

**Why:**

- **Simplicity vs Scalability Balance:** For 100-1000 records/day, a single table is optimal. Reduces join complexity and query overhead.
- **Status Column:** Enables state machine pattern (pending ‚Üí processing ‚Üí completed/failed) which prevents:
  - Duplicate processing (concurrent API calls to same record)
  - Lost track of failures
  - Unclear system state
- **JSONB for Analysis:** OpenAI responses can vary in structure. JSONB provides:
  - Flexibility for different analysis types
  - Fast querying with GIN indexes
  - Easy schema evolution without migrations

**Tradeoffs Considered:**

- **Alternative 1:** Separate `raw_data` and `analyses` tables
  - ‚ùå More complex queries
  - ‚ùå Additional join overhead
  - ‚úÖ Better for 100K+ records/day with complex analytics

- **Alternative 2:** NULL-based analysis tracking
  - ‚ùå Can't distinguish "not processed" from "failed"
  - ‚ùå No retry logic possible
  - ‚ùå Poor observability

**Chosen approach wins for this scale:** Clear, queryable, prevents race conditions, enables retries.

### 2. Workflow Explanation

**End-to-End Flow:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Apify   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Supabase ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ OpenAI  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   UI    ‚îÇ
‚îÇ Scraper ‚îÇ      ‚îÇ Storage  ‚îÇ      ‚îÇ Analysis‚îÇ      ‚îÇ Display ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Detailed Steps:**

1. **Data Collection (Apify)**
   - User clicks "Run Pipeline" button
   - `/api/scrape` endpoint calls Apify Reddit scraper actor
   - Configures: 3 subreddits, 25 posts max, skip comments
   - Apify returns dataset with post titles and bodies
   - Records inserted into Supabase with `status='pending'`

2. **Storage (Supabase)**
   - Each record gets unique UUID
   - Indexed by `created_at` for fast recent queries
   - Indexed by `status` for efficient batch processing
   - Client can query in real-time (no polling needed with Supabase realtime)

3. **Analysis (OpenAI)**
   - `/api/analyze` queries for `status='pending'` records (LIMIT 10)
   - Sets `status='processing'` before API call (prevents duplicates)
   - Sends each post to GPT-3.5 with structured prompt
   - Prompt requests JSON response: `{sentiment: string, summary: string}`
   - On success: Updates record with analysis, `status='completed'`, `analyzed_at` timestamp
   - On failure: Sets `status='failed'`, stores error message

4. **Display (Next.js)**
   - Frontend queries Supabase directly (browser-safe client)
   - Displays all records with status badges and sentiment colors
   - "Retry Failed" button queries `status='failed'` records
   - Toast notifications provide real-time feedback

**State Transitions:**

```
pending ‚Üí processing ‚Üí completed ‚úì
                    ‚Üí failed ‚ùå (retryable)
```

---

## üìà Scaling Considerations

### Current System Capacity

- **Current:** ~100-500 records/day
- **Bottlenecks:** Sequential OpenAI calls, API rate limits, single server

### Scaling to 100,000 Records/Day

**1. Queue System (First Priority)**

**Problem:** Sequential processing is too slow

**Solution:** Implement job queue with BullMQ + Redis

```typescript
// Example implementation
import Queue from 'bullmq'

const analysisQueue = new Queue('analysis', {
  connection: REDIS_URL
})

// Producer: Add jobs instead of processing immediately
await analysisQueue.add('analyze-post', { recordId })

// Consumer: Process in parallel with concurrency control
worker.process('analyze-post', async (job) => {
  await analyzeRecord(job.data.recordId)
})
```

**Benefits:**
- Process 100+ records concurrently
- Automatic retry with exponential backoff
- Job prioritization
- Persistent queue (survives server restarts)

**2. Batch Processing**

**Current:** 10 records per API call
**Scaled:** 100 records per batch, multiple workers

```typescript
// Horizontal scaling with multiple workers
const workers = Array.from({ length: 10 }, () => 
  new Worker('analysis-queue', processJob, {
    concurrency: 10 // Each worker handles 10 concurrent jobs
  })
)
// Total: 100 concurrent analyses
```

**3. Database Optimization**

**Add Partitioning:**
```sql
-- Partition by date for fast queries
CREATE TABLE analyzed_data_2024_01 PARTITION OF analyzed_data
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
```

**Add Caching:**
- Redis cache for frequently accessed data
- Cache sentiment distribution stats
- Reduce DB load by 80%

**4. API Rate Limits Management**

**OpenAI Limits:** 3,500 requests/min (GPT-3.5)

**Solution:**
- Token bucket algorithm for rate limiting
- Multiple API keys rotation
- Fallback to alternative models during peak

```typescript
const rateLimiter = new RateLimiter({
  tokensPerInterval: 3500,
  interval: 'minute'
})

await rateLimiter.removeTokens(1)
await openai.chat.completions.create(...)
```

**5. Horizontal Scaling**

- Deploy multiple Vercel instances (automatic)
- Shared queue via Redis
- Distributed locks prevent duplicate processing

**Expected Performance:**
- **Current:** ~500 records/hour
- **With queue:** ~10,000 records/hour
- **With 10 workers:** ~100,000 records/hour
- **Cost:** ~$50/day for OpenAI API at scale

---

## üõ° Failure Handling Strategy

### Types of Failures & Responses

#### 1. Apify API Failures

**Scenarios:**
- Rate limit exceeded
- Actor timeout
- Network errors
- Invalid credentials

**Handling:**
```typescript
try {
  const run = await apifyClient.actor('...').call()
} catch (error) {
  if (error.statusCode === 429) {
    // Rate limit - exponential backoff
    await sleep(Math.pow(2, retryCount) * 1000)
    return retry()
  }
  
  if (error.statusCode === 504) {
    // Timeout - increase timeout and retry
    return retryWithLongerTimeout()
  }
  
  // Log error, alert ops team
  logger.error('Apify failure', { error, context })
  return { error: 'scraping_failed', retryable: true }
}
```

**Why:** Temporary failures shouldn't stop the entire pipeline

#### 2. OpenAI API Failures

**Scenarios:**
- Rate limits (TPM/RPM exceeded)
- Content policy violations
- Service outages
- Malformed responses

**Handling:**
```typescript
// Individual record failure doesn't fail the batch
const results = await Promise.allSettled(
  records.map(async (record) => {
    try {
      const analysis = await openai.chat.completions.create(...)
      await updateRecord(record.id, 'completed', analysis)
    } catch (error) {
      if (error.code === 'rate_limit_exceeded') {
        // Mark as pending, will retry in next batch
        await updateRecord(record.id, 'pending', null)
      } else {
        // Mark as failed with error message
        await updateRecord(record.id, 'failed', null, error.message)
      }
    }
  })
)
```

**Why:** One bad record shouldn't block 99 good ones

#### 3. Supabase/Database Failures

**Scenarios:**
- Connection timeouts
- Write conflicts
- Schema mismatches

**Handling:**
```typescript
// Retry with exponential backoff
async function insertWithRetry(data, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await supabase.from('analyzed_data').insert(data)
    } catch (error) {
      if (i === maxRetries - 1) throw error
      await sleep(Math.pow(2, i) * 1000)
    }
  }
}
```

**Why:** Network blips are common, simple retries solve 95% of issues

### Retry Strategy

**Status-Based Retries:**

```typescript
// Automatic: Process failed records separately
const { data: failedRecords } = await supabase
  .from('analyzed_data')
  .select('*')
  .eq('status', 'failed')
  .lt('retry_count', 3) // Max 3 retries

// Exponential backoff between retries
const backoffSeconds = Math.pow(2, retryCount) * 60 // 1min, 2min, 4min
```

**Manual Retry:** "Retry Failed" button in UI for user-initiated retries

### Dead Letter Queue (DLQ)

For records that fail 3+ times:

```sql
-- Move to DLQ for manual investigation
CREATE TABLE analysis_dlq (
  id UUID,
  original_record_id UUID,
  error_message TEXT,
  retry_count INT,
  created_at TIMESTAMPTZ
);
```

**Alert Ops Team:**
- Slack notification when DLQ > 100 records
- Daily summary of failure types
- Automated fallback to simpler analysis model

### Graceful Degradation

If OpenAI is down:
1. Continue scraping (data collection unaffected)
2. Mark records as `pending` for later analysis
3. Display "Analysis pending" in UI
4. Process backlog when service recovers

**Why:** System remains partially functional, no data loss

---

## üè• System Health Monitoring (Bonus)

### Health Endpoint

**Route:** `GET /api/health`

**Returns:**
```json
{
  "status": "healthy",
  "timestamp": "2024-11-09T12:00:00Z",
  "metrics": {
    "total": 150,
    "byStatus": {
      "pending": 5,
      "processing": 2,
      "completed": 140,
      "failed": 3
    },
    "lastAnalyzedAt": "2024-11-09T11:58:32Z"
  },
  "summary": {
    "successRate": "93.3%",
    "failureRate": "2.0%"
  }
}
```

### Health Status Logic

```typescript
const healthStatus = 
  failedCount > completedCount * 0.5 ? 'degraded' :
  processingCount > 5 ? 'processing' :
  totalCount === 0 ? 'idle' : 'healthy'
```

### Uptime Monitoring Strategy

**1. External Monitoring (Recommended)**

Use services like Uptime Robot, Better Uptime, or Datadog:

```bash
# Monitor every 5 minutes
GET https://your-app.vercel.app/api/health
```

**Alert if:**
- Status returns `degraded` for 3+ consecutive checks
- Response time > 5 seconds
- Failure rate > 10%
- No analyses in past 1 hour

**2. Internal Monitoring**

```typescript
// Scheduled job (cron)
export async function checkHealth() {
  const health = await fetch('/api/health').then(r => r.json())
  
  if (health.status === 'degraded') {
    await sendSlackAlert({
      text: `‚ö†Ô∏è System degraded: ${health.summary.failureRate} failure rate`,
      channel: '#alerts'
    })
  }
  
  // Log to monitoring service
  await datadog.gauge('app.records.total', health.metrics.total)
  await datadog.gauge('app.records.failed', health.metrics.byStatus.failed)
}
```

**3. Dashboard Visualization**

The `/api/health` endpoint could power a status page:

- Real-time metrics graph (records processed over time)
- Success rate chart
- Average processing time
- API usage stats

**Benefits:**
- **Proactive alerts** before users notice issues
- **SLA tracking** for uptime guarantees
- **Debugging** - correlate errors with deployment times
- **Capacity planning** - identify scaling needs early

---

## üì∏ Screenshots

### Supabase Database

![Supabase Table](screenshots/supabase-table.png)
*Table view showing analyzed records with status, sentiment, and timestamps*

![Analysis Results](screenshots/supabase-analysis.png)
*Detailed view of OpenAI analysis results stored in JSONB column*

### Application UI

![Main Interface](screenshots/ui-main.png)
*Fighter Jet Analyzer interface with analyzed discussions*

![System Health](screenshots/health-endpoint.png)
*Health monitoring endpoint showing system metrics*

---

## üéì Key Learnings

### Technical Insights

1. **State machines are powerful** - The status column pattern prevented countless race condition bugs
2. **Batch processing matters** - Sequential API calls don't scale, even at small volume
3. **Error messages are features** - Storing `error_message` column made debugging 10x faster
4. **JSON response format** - OpenAI's structured output mode eliminated parsing errors

### Production Thinking

1. **Observability first** - The health endpoint took 15 minutes but demonstrates production mindset
2. **Retry logic is essential** - Network failures are guaranteed, plan for them upfront
3. **User feedback matters** - Toast notifications transformed UX from confusing to clear
4. **Status visibility** - Showing pending/processing/failed states builds user trust

---

## üìù License

MIT License - Feel free to use this project as a reference or starting point!

---

## üôè Acknowledgments

- **Apify** for powerful web scraping infrastructure
- **Supabase** for managed PostgreSQL with real-time capabilities
- **OpenAI** for accessible AI analysis APIs
- **Next.js** for excellent developer experience

---

**Built with ‚ù§Ô∏è for the Full-Stack Developer Technical Challenge**
